<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Active 6D Pose Estimation for Textureless Objects using Multi-View RGB Frames.">
  <meta name="keywords" content="6D Object Pose, Multi-view Optimization, Active Vision, Deep Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Active 6D Pose Estimation for Textureless Objects using Multi-View RGB Frames</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Active 6D Pose Estimation for Textureless Objects using Multi-View RGB Frames</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Jun Yang<sup>1, 2</sup>,</span>
            <span class="author-block">
              Wenjie Xue<sup>2</sup>,</span>
            <span class="author-block">
              Sahar Ghavidel<sup>2</sup>,
            </span>
            <span class="author-block">
              Steven L. Waslander<sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Toronto Institute for Aerospace Studies and Robotics Institute,</span>
            <span class="author-block"><sup>2</sup>Epson Canada Ltd.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.03726"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
<!--              &lt;!&ndash; Code Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/TRAILab/ActiveODPE"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-github"></i>-->
<!--                  </span>-->
<!--                  <span>Code</span>-->
<!--                  </a>-->
<!--              </span>-->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://www.trailab.utias.utoronto.ca/t-robi-dataset"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
               <!-- Evaluation Link. -->
              <span class="link-block">
                <a href="https://github.com/TRAILab/ActiveODPE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-chart-bar"></i>
                  </span>
                  <span>Evaluation</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
<!--    <div class="hero-body">-->
<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--        <source src="./static/videos/teaser.mp4"-->
<!--                type="video/mp4">-->
<!--      </video>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into-->
<!--        free-viewpoint-->
<!--        portraits.-->
<!--      </h2>-->
<!--    </div>-->
    <div class="hero-body">
      <img src="./static/images/Figure%202.png" alt="Pipeline overview"/>
      <p><strong> In this work, we present a complete framework of multi-view
pose estimation and next-best-view prediction for textureless
        objects.</strong></p>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Estimating the 6D pose of textureless objects from RBG images is an important problem in robotics. Due to appearance
ambiguities, rotational symmetries, and severe occlusions, single-view based 6D pose estimators are still unable to
handle a wide range of objects, motivating research towards multi-view pose estimation and next-best-view prediction
that addresses these limitations.
          </p>
          <p>
 In this work, we propose a comprehensive active perception framework for estimating
the 6D poses of textureless objects using only RGB images. Our approach is built upon a key idea: decoupling the 6D
pose estimation into a sequential two-step process can greatly improve both accuracy and efficiency. First, we estimate
the 3D translation of each object, resolving scale and depth ambiguities inherent to RGB images. These estimates
are then used to simplify the subsequent task of determining the 3D orientation, which we achieve through canonical
scale template matching. Building on this formulation, we then introduce an active perception strategy that predicts
the next best camera viewpoint to capture an RGB image, effectively reducing object pose uncertainty and enhancing
pose accuracy.
          </p>
          <p>
We evaluate our method on the public ROBI dataset as well as on a transparent object dataset that we
created. When evaluated using the same camera viewpoints, our multi-view pose estimation significantly outperforms
state-of-the-art approaches. Furthermore, by leveraging our next-best-view strategy, our method achieves high object
pose accuracy with substantially fewer viewpoints than heuristic-based policies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
    <!--/ Abstract. -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{yang2025active6dposeestimation,
      title={Active 6D Pose Estimation for Textureless Objects using Multi-View RGB Frames},
      author={Jun Yang and Wenjie Xue and Sahar Ghavidel and Steven L. Waslander},
      year={2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link" href="">
        <i class="fas fa-file-pdf"></i>
      </a> -->
      <!-- <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i> -->
<!--      </a>-->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We thank the authors of <a href="https://nerfies.github.io/">Nerfies</a> that kindly open sourced the
            template of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>